{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1593ae9b",
   "metadata": {},
   "source": [
    "# ARIMA-GARCH Hybrid Model\n",
    "\n",
    "**Objective**: Two-stage model for financial returns\n",
    "- **Stage 1 (ARIMA)**: Model the conditional mean (expected return)\n",
    "- **Stage 2 (GARCH)**: Model the conditional variance (volatility)\n",
    "\n",
    "**Motivation**: Financial returns exhibit **volatility clustering** (heteroskedasticity)\n",
    "- ARIMA assumes constant variance → violated in financial data\n",
    "- GARCH captures time-varying volatility\n",
    "\n",
    "**Implementation**: Following Section 8 of methodology document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31855dd",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75acd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ARIMA modeling\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import pmdarima as pm\n",
    "\n",
    "# GARCH modeling\n",
    "from arch import arch_model\n",
    "from arch.univariate import ConstantMean, GARCH, Normal\n",
    "\n",
    "# Statistical tests\n",
    "from statsmodels.stats.diagnostic import het_arch\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45046818",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65488281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('../data/gold_silver.csv')\n",
    "\n",
    "# Convert to datetime and set frequency\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "df = df.sort_values('DATE')\n",
    "df.set_index('DATE', inplace=True)\n",
    "df = df.asfreq('B')  # Business Day frequency\n",
    "\n",
    "# Calculate log returns\n",
    "df['GOLD_LOG_RETURN'] = np.log(df['GOLD_PRICE']) - np.log(df['GOLD_PRICE'].shift(1))\n",
    "df = df.dropna(subset=['GOLD_LOG_RETURN'])\n",
    "\n",
    "print(f\"Dataset: {len(df)} observations\")\n",
    "print(f\"Date range: {df.index.min()} to {df.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d0c993",
   "metadata": {},
   "source": [
    "## 3. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c443689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80-20 split\n",
    "train_size = int(len(df) * 0.8)\n",
    "train = df['GOLD_LOG_RETURN'].iloc[:train_size]\n",
    "test = df['GOLD_LOG_RETURN'].iloc[train_size:]\n",
    "\n",
    "train_prices = df['GOLD_PRICE'].iloc[:train_size]\n",
    "test_prices = df['GOLD_PRICE'].iloc[train_size:]\n",
    "\n",
    "print(f\"Train set: {len(train)} observations\")\n",
    "print(f\"Test set:  {len(test)} observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e97c1db",
   "metadata": {},
   "source": [
    "## 4. Stage 1: Fit ARIMA for Conditional Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c47421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use auto_arima to find optimal order\n",
    "print(\"Stage 1: Finding optimal ARIMA order...\\n\")\n",
    "\n",
    "auto_model = pm.auto_arima(\n",
    "    train,\n",
    "    start_p=0, max_p=5,\n",
    "    start_q=0, max_q=5,\n",
    "    d=0,\n",
    "    seasonal=False,\n",
    "    stepwise=True,\n",
    "    suppress_warnings=True,\n",
    "    error_action='ignore',\n",
    "    trace=True,\n",
    "    information_criterion='aic'\n",
    ")\n",
    "\n",
    "best_order = auto_model.order\n",
    "print(f\"\\n✓ Best ARIMA order: {best_order}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4674418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ARIMA model\n",
    "arima_model = ARIMA(train, order=best_order)\n",
    "arima_fit = arima_model.fit()\n",
    "\n",
    "print(\"✓ ARIMA model fitted\")\n",
    "print(f\"\\nARIMA{best_order} Summary:\")\n",
    "print(f\"AIC: {arima_fit.aic:.2f}\")\n",
    "print(f\"BIC: {arima_fit.bic:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c93f9e",
   "metadata": {},
   "source": [
    "## 5. Extract Residuals and Test for ARCH Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb00b0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract standardized residuals from ARIMA\n",
    "residuals = arima_fit.resid\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TESTING FOR ARCH EFFECTS (Heteroskedasticity)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Engle's ARCH test\n",
    "# H0: No ARCH effects (homoskedastic)\n",
    "# H1: ARCH effects present (heteroskedastic)\n",
    "arch_test = het_arch(residuals, nlags=10)\n",
    "\n",
    "print(f\"\\nEngle's ARCH Test (10 lags):\")\n",
    "print(f\"  LM Statistic: {arch_test[0]:.4f}\")\n",
    "print(f\"  p-value:      {arch_test[1]:.6f}\")\n",
    "print(f\"  F-statistic:  {arch_test[2]:.4f}\")\n",
    "print(f\"  F p-value:    {arch_test[3]:.6f}\")\n",
    "\n",
    "if arch_test[1] < 0.05:\n",
    "    print(f\"\\n✓ ARCH effects detected (p < 0.05) → GARCH modeling is appropriate\")\n",
    "else:\n",
    "    print(f\"\\n⚠ No significant ARCH effects (p ≥ 0.05) → GARCH may not improve fit\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc6c0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual inspection: ACF of squared residuals\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ACF of residuals\n",
    "plot_acf(residuals, lags=40, ax=axes[0])\n",
    "axes[0].set_title('ACF of ARIMA Residuals', fontsize=12, fontweight='bold')\n",
    "\n",
    "# ACF of squared residuals (ARCH test)\n",
    "plot_acf(residuals**2, lags=40, ax=axes[1])\n",
    "axes[1].set_title('ACF of Squared Residuals (Volatility Clustering)', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Significant lags in squared residuals ACF → volatility clustering\")\n",
    "print(\"- This confirms the need for GARCH modeling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6287818c",
   "metadata": {},
   "source": [
    "## 6. Stage 2: Fit GARCH on ARIMA Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ea6e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit GARCH(1,1) model on residuals\n",
    "print(\"Stage 2: Fitting GARCH(1,1) on ARIMA residuals...\\n\")\n",
    "\n",
    "# Scale residuals by 100 for numerical stability\n",
    "residuals_scaled = residuals * 100\n",
    "\n",
    "# Specify GARCH model\n",
    "garch_model = arch_model(\n",
    "    residuals_scaled,\n",
    "    mean='Zero',  # No mean model (already modeled by ARIMA)\n",
    "    vol='GARCH',  # GARCH volatility\n",
    "    p=1,          # GARCH order\n",
    "    q=1,          # ARCH order\n",
    "    dist='normal' # Normal distribution\n",
    ")\n",
    "\n",
    "# Fit GARCH\n",
    "garch_fit = garch_model.fit(disp='off')\n",
    "\n",
    "print(\"✓ GARCH(1,1) model fitted\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GARCH MODEL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(garch_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d8f725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract conditional volatility (scaled back)\n",
    "conditional_volatility = garch_fit.conditional_volatility / 100\n",
    "\n",
    "# Plot conditional volatility\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Residuals\n",
    "axes[0].plot(residuals.index, residuals, linewidth=0.5, alpha=0.7, label='Residuals')\n",
    "axes[0].axhline(y=0, color='black', linestyle='--')\n",
    "axes[0].set_title('ARIMA Residuals', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Residual', fontsize=11)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Conditional volatility from GARCH\n",
    "axes[1].plot(conditional_volatility.index, conditional_volatility, color='red', linewidth=1, label='Conditional Volatility')\n",
    "axes[1].set_title('GARCH Conditional Volatility (Time-Varying Risk)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Volatility', fontsize=11)\n",
    "axes[1].set_xlabel('Date', fontsize=11)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Conditional volatility successfully modeled\")\n",
    "print(\"\\nKey Insight: Volatility changes over time (high during crises, low during stability)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca071da",
   "metadata": {},
   "source": [
    "## 7. Hybrid Model: Combined ARIMA-GARCH Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a3947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk-forward validation with hybrid model\n",
    "forecast_horizon = 5\n",
    "predictions_mean = []  # From ARIMA\n",
    "predictions_vol = []   # From GARCH\n",
    "actuals_log = []\n",
    "predictions_price = []\n",
    "actuals_price = []\n",
    "\n",
    "print(\"Running walk-forward validation with ARIMA-GARCH...\")\n",
    "print(f\"Forecast horizon: {forecast_horizon} days\\n\")\n",
    "\n",
    "# Use expanding window\n",
    "for i in range(0, len(test) - forecast_horizon, forecast_horizon):\n",
    "    # Expanding train data\n",
    "    train_data = pd.concat([train, test.iloc[:i]])\n",
    "    \n",
    "    # Fit ARIMA\n",
    "    arima_temp = ARIMA(train_data, order=best_order)\n",
    "    arima_fit_temp = arima_temp.fit()\n",
    "    \n",
    "    # Get residuals and fit GARCH\n",
    "    resid_temp = arima_fit_temp.resid * 100\n",
    "    garch_temp = arch_model(resid_temp, mean='Zero', vol='GARCH', p=1, q=1)\n",
    "    garch_fit_temp = garch_temp.fit(disp='off')\n",
    "    \n",
    "    # Forecast mean (ARIMA)\n",
    "    forecast_mean = arima_fit_temp.forecast(steps=forecast_horizon)\n",
    "    \n",
    "    # Forecast volatility (GARCH)\n",
    "    forecast_vol = garch_fit_temp.forecast(horizon=forecast_horizon)\n",
    "    forecast_variance = forecast_vol.variance.values[-1, :] / 10000  # Scale back\n",
    "    forecast_std = np.sqrt(forecast_variance)\n",
    "    \n",
    "    # Store forecasts\n",
    "    predictions_mean.extend(forecast_mean.values)\n",
    "    predictions_vol.extend(forecast_std)\n",
    "    \n",
    "    # Actuals\n",
    "    actual_log = test.iloc[i:i+forecast_horizon]\n",
    "    actuals_log.extend(actual_log.values)\n",
    "    \n",
    "    # Convert to prices\n",
    "    last_price = df['GOLD_PRICE'].iloc[train_size + i - 1]\n",
    "    for j in range(len(forecast_mean)):\n",
    "        pred_price = last_price * np.exp(forecast_mean.iloc[j])\n",
    "        actual_price = df['GOLD_PRICE'].iloc[train_size + i + j]\n",
    "        predictions_price.append(pred_price)\n",
    "        actuals_price.append(actual_price)\n",
    "        last_price = pred_price\n",
    "    \n",
    "    if (i // forecast_horizon + 1) % 10 == 0:\n",
    "        print(f\"  Progress: {i+forecast_horizon}/{len(test)} forecasts\")\n",
    "\n",
    "print(f\"\\n✓ Generated {len(predictions_price)} forecasts (mean + volatility)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e480564c",
   "metadata": {},
   "source": [
    "## 8. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e288de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics on PRICES\n",
    "rmse = np.sqrt(mean_squared_error(actuals_price, predictions_price))\n",
    "mae = mean_absolute_error(actuals_price, predictions_price)\n",
    "\n",
    "# Load previous model results\n",
    "try:\n",
    "    arima_results = pd.read_csv('../models/arima_baseline_results.csv')\n",
    "    rmse_arima = arima_results['rmse'].values[0]\n",
    "    mae_arima = arima_results['mae'].values[0]\n",
    "    rmse_naive = arima_results['rmse_naive'].values[0]\n",
    "    mae_naive = arima_results['mae_naive'].values[0]\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"MODEL COMPARISON - 5-DAY AHEAD FORECASTS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nARIMA-GARCH Hybrid:\")\n",
    "    print(f\"  RMSE: ${rmse:.2f}\")\n",
    "    print(f\"  MAE:  ${mae:.2f}\")\n",
    "    print(f\"  + Volatility forecasts available\")\n",
    "    print(f\"\\nARIMA Baseline:\")\n",
    "    print(f\"  RMSE: ${rmse_arima:.2f}\")\n",
    "    print(f\"  MAE:  ${mae_arima:.2f}\")\n",
    "    print(f\"\\nNaive Benchmark:\")\n",
    "    print(f\"  RMSE: ${rmse_naive:.2f}\")\n",
    "    print(f\"  MAE:  ${mae_naive:.2f}\")\n",
    "    print(f\"\\nImprovement over ARIMA:\")\n",
    "    print(f\"  RMSE: {(1 - rmse/rmse_arima)*100:+.2f}%\")\n",
    "    print(f\"  MAE:  {(1 - mae/mae_arima)*100:+.2f}%\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\nNote: ARIMA-GARCH provides TWO outputs:\")\n",
    "    print(\"  1. Point forecast (mean) - measured by RMSE/MAE\")\n",
    "    print(\"  2. Volatility forecast (risk) - critical for portfolio management\")\n",
    "except:\n",
    "    print(\"⚠ Previous results not found\")\n",
    "    print(f\"\\nARIMA-GARCH Results:\")\n",
    "    print(f\"  RMSE: ${rmse:.2f}\")\n",
    "    print(f\"  MAE:  ${mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b2ceb7",
   "metadata": {},
   "source": [
    "## 9. Visualize Forecasts with Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7ca859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions with volatility bands\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Price forecasts with confidence intervals\n",
    "forecast_dates = test.index[:len(predictions_price)]\n",
    "pred_array = np.array(predictions_price)\n",
    "vol_array = np.array(predictions_vol[:len(predictions_price)])\n",
    "\n",
    "# Convert volatility to price scale\n",
    "upper_band = pred_array * np.exp(1.96 * vol_array)  # 95% CI\n",
    "lower_band = pred_array * np.exp(-1.96 * vol_array)\n",
    "\n",
    "axes[0].plot(forecast_dates, actuals_price, label='Actual Price', color='black', linewidth=1.5)\n",
    "axes[0].plot(forecast_dates, predictions_price, label='ARIMA-GARCH Forecast', color='purple', linewidth=1.5, alpha=0.7)\n",
    "axes[0].fill_between(forecast_dates, lower_band, upper_band, alpha=0.2, color='purple', label='95% Confidence Interval')\n",
    "axes[0].set_title('ARIMA-GARCH: Gold Price Forecasts with Uncertainty', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Price (USD)', fontsize=11)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Forecasted volatility\n",
    "axes[1].plot(forecast_dates, predictions_vol[:len(forecast_dates)], color='red', linewidth=1.5, label='Forecast Volatility')\n",
    "axes[1].set_title('GARCH: Forecasted Volatility (Risk)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Volatility (Log Return Std)', fontsize=11)\n",
    "axes[1].set_xlabel('Date', fontsize=11)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adfa9a8",
   "metadata": {},
   "source": [
    "## 10. Save Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ffb500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results = {\n",
    "    'model': f'ARIMA{best_order}-GARCH(1,1)',\n",
    "    'rmse': rmse,\n",
    "    'mae': mae,\n",
    "    'n_predictions': len(predictions_price),\n",
    "    'arima_order': str(best_order),\n",
    "    'garch_order': '(1,1)'\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame([results])\n",
    "results_df.to_csv('../models/arima_garch_results.csv', index=False)\n",
    "\n",
    "# Save models\n",
    "arima_fit.save('../models/arima_garch_stage1.pkl')\n",
    "# Note: GARCH models are refitted in walk-forward, no single model to save\n",
    "\n",
    "print(\"✓ Results saved\")\n",
    "print(\"\\nFiles created:\")\n",
    "print(\"  - arima_garch_results.csv\")\n",
    "print(\"  - arima_garch_stage1.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeb4984",
   "metadata": {},
   "source": [
    "## 11. Key Findings\n",
    "\n",
    "**ARIMA-GARCH Advantages**:\n",
    "1. **Dual Output**: Point forecast (mean) + Volatility forecast (risk)\n",
    "2. **Captures Heteroskedasticity**: Models time-varying volatility\n",
    "3. **Financial Applications**:\n",
    "   - Risk management (VaR, CVaR)\n",
    "   - Options pricing (volatility input)\n",
    "   - Portfolio optimization (risk-adjusted returns)\n",
    "\n",
    "**Limitations**:\n",
    "- Still linear in mean equation\n",
    "- Assumes symmetric volatility response\n",
    "- For asymmetry (leverage effect), use EGARCH or TGARCH\n",
    "\n",
    "**Next**: Compare with LSTM (Notebook 05) for non-linear alternative"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
