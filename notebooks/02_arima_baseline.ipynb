{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4ec0d84",
   "metadata": {},
   "source": [
    "# ARIMA Baseline Model (Endogenous Only)\n",
    "\n",
    "**Objective**: Build a simple ARIMA model using only historical log returns (no exogenous variables)\n",
    "\n",
    "**Model**: ARIMA(p, 0, q) where:\n",
    "- p, q are determined by `pmdarima.auto_arima()`\n",
    "- d=0 because we model stationary log returns\n",
    "- No seasonal component (baseline)\n",
    "- No exogenous variables (pure time series)\n",
    "\n",
    "**Purpose**: Establish performance benchmark for comparison with SARIMAX and GARCH models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61243fa1",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4758d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ARIMA modeling\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import pmdarima as pm\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c55aa4",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08de4b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('../data/gold_silver.csv')\n",
    "\n",
    "# Convert to datetime and set frequency\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "df = df.sort_values('DATE')\n",
    "df.set_index('DATE', inplace=True)\n",
    "df = df.asfreq('B')  # Business Day frequency\n",
    "\n",
    "# Calculate log returns\n",
    "df['GOLD_LOG_RETURN'] = np.log(df['GOLD_PRICE']) - np.log(df['GOLD_PRICE'].shift(1))\n",
    "df = df.dropna(subset=['GOLD_LOG_RETURN'])\n",
    "\n",
    "print(f\"Dataset: {len(df)} observations\")\n",
    "print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
    "print(f\"\\nLog Returns Summary:\")\n",
    "print(df['GOLD_LOG_RETURN'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82df59a",
   "metadata": {},
   "source": [
    "## 3. Train-Test Split (Chronological)\n",
    "\n",
    "**Critical**: Use temporal split, NO shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d655df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80-20 split\n",
    "train_size = int(len(df) * 0.8)\n",
    "train = df['GOLD_LOG_RETURN'].iloc[:train_size]\n",
    "test = df['GOLD_LOG_RETURN'].iloc[train_size:]\n",
    "\n",
    "# Store original prices for later transformation\n",
    "train_prices = df['GOLD_PRICE'].iloc[:train_size]\n",
    "test_prices = df['GOLD_PRICE'].iloc[train_size:]\n",
    "\n",
    "print(f\"Train set: {len(train)} observations ({train.index.min()} to {train.index.max()})\")\n",
    "print(f\"Test set:  {len(test)} observations ({test.index.min()} to {test.index.max()})\")\n",
    "print(f\"\\nTest set represents {len(test)/len(df)*100:.1f}% of data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a68ea5b",
   "metadata": {},
   "source": [
    "## 4. Model Selection with auto_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b778cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use auto_arima to find optimal (p, q)\n",
    "print(\"Running auto_arima... (this may take a few minutes)\\n\")\n",
    "\n",
    "auto_model = pm.auto_arima(\n",
    "    train,\n",
    "    start_p=0, max_p=5,\n",
    "    start_q=0, max_q=5,\n",
    "    d=0,  # Already stationary (log returns)\n",
    "    seasonal=False,  # No seasonality in baseline\n",
    "    stepwise=True,\n",
    "    suppress_warnings=True,\n",
    "    error_action='ignore',\n",
    "    trace=True,\n",
    "    information_criterion='aic'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"OPTIMAL MODEL FOUND\")\n",
    "print(\"=\"*70)\n",
    "print(auto_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39afaa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract optimal orders\n",
    "best_order = auto_model.order\n",
    "print(f\"\\nBest ARIMA order: {best_order}\")\n",
    "print(f\"AIC: {auto_model.aic():.2f}\")\n",
    "print(f\"BIC: {auto_model.bic():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7d5765",
   "metadata": {},
   "source": [
    "## 5. Fit Final ARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e52cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ARIMA with optimal parameters\n",
    "model = ARIMA(train, order=best_order)\n",
    "arima_fit = model.fit()\n",
    "\n",
    "print(\"✓ ARIMA model fitted successfully\")\n",
    "print(f\"\\nModel: ARIMA{best_order}\")\n",
    "print(f\"Log-Likelihood: {arima_fit.llf:.2f}\")\n",
    "print(f\"AIC: {arima_fit.aic:.2f}\")\n",
    "print(f\"BIC: {arima_fit.bic:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff73c9d",
   "metadata": {},
   "source": [
    "## 6. Residual Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e20e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals\n",
    "residuals = arima_fit.resid\n",
    "\n",
    "# Plot residuals\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Residuals over time\n",
    "axes[0, 0].plot(residuals, linewidth=0.5)\n",
    "axes[0, 0].axhline(y=0, color='red', linestyle='--')\n",
    "axes[0, 0].set_title('Residuals Over Time', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Residual')\n",
    "\n",
    "# Histogram\n",
    "axes[0, 1].hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].set_title('Residuals Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Residual')\n",
    "\n",
    "# ACF\n",
    "plot_acf(residuals, lags=40, ax=axes[1, 0])\n",
    "axes[1, 0].set_title('ACF of Residuals', fontsize=12, fontweight='bold')\n",
    "\n",
    "# ACF of squared residuals (ARCH test)\n",
    "plot_acf(residuals**2, lags=40, ax=axes[1, 1])\n",
    "axes[1, 1].set_title('ACF of Squared Residuals (ARCH Effects)', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Residuals Mean: {residuals.mean():.6f} (should be ~0)\")\n",
    "print(f\"Residuals Std: {residuals.std():.6f}\")\n",
    "print(f\"\\n⚠ If ACF of squared residuals shows significant lags → ARCH effects present → GARCH needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a582abe1",
   "metadata": {},
   "source": [
    "## 7. Walk-Forward Validation (5-Day Ahead Forecasts)\n",
    "\n",
    "**Strategy**: Rolling window with 5-step ahead forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3874b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk-forward validation setup\n",
    "forecast_horizon = 5  # 5 days ahead (one trading week)\n",
    "predictions_log = []\n",
    "actuals_log = []\n",
    "predictions_price = []\n",
    "actuals_price = []\n",
    "\n",
    "print(\"Running walk-forward validation...\")\n",
    "print(f\"Forecast horizon: {forecast_horizon} days\")\n",
    "print(f\"Test set size: {len(test)}\")\n",
    "\n",
    "# Use expanding window (not rolling)\n",
    "for i in range(0, len(test) - forecast_horizon, forecast_horizon):\n",
    "    # Train data: all past observations\n",
    "    train_data = pd.concat([train, test.iloc[:i]])\n",
    "    \n",
    "    # Fit model\n",
    "    model_temp = ARIMA(train_data, order=best_order)\n",
    "    fit_temp = model_temp.fit()\n",
    "    \n",
    "    # Forecast 5 steps ahead\n",
    "    forecast_log = fit_temp.forecast(steps=forecast_horizon)\n",
    "    actual_log = test.iloc[i:i+forecast_horizon]\n",
    "    \n",
    "    predictions_log.extend(forecast_log.values)\n",
    "    actuals_log.extend(actual_log.values)\n",
    "    \n",
    "    # Convert log returns to prices\n",
    "    last_price = df['GOLD_PRICE'].iloc[train_size + i - 1]\n",
    "    for j in range(len(forecast_log)):\n",
    "        pred_price = last_price * np.exp(forecast_log.iloc[j])\n",
    "        actual_price = df['GOLD_PRICE'].iloc[train_size + i + j]\n",
    "        predictions_price.append(pred_price)\n",
    "        actuals_price.append(actual_price)\n",
    "        last_price = pred_price  # Iterative approach\n",
    "\n",
    "print(f\"✓ Generated {len(predictions_price)} forecasts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2472666",
   "metadata": {},
   "source": [
    "## 8. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6ee9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics on PRICES (not log returns)\n",
    "rmse = np.sqrt(mean_squared_error(actuals_price, predictions_price))\n",
    "mae = mean_absolute_error(actuals_price, predictions_price)\n",
    "\n",
    "# Naive benchmark (Random Walk: price_t = price_t-1)\n",
    "naive_predictions = test_prices.shift(forecast_horizon).dropna().values[:len(actuals_price)]\n",
    "naive_actuals = actuals_price[:len(naive_predictions)]\n",
    "rmse_naive = np.sqrt(mean_squared_error(naive_actuals, naive_predictions))\n",
    "mae_naive = mean_absolute_error(naive_actuals, naive_predictions)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MODEL EVALUATION - 5-DAY AHEAD FORECASTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nARIMA{best_order} Model:\")\n",
    "print(f\"  RMSE: ${rmse:.2f}\")\n",
    "print(f\"  MAE:  ${mae:.2f}\")\n",
    "print(f\"\\nNaive Benchmark (Random Walk):\")\n",
    "print(f\"  RMSE: ${rmse_naive:.2f}\")\n",
    "print(f\"  MAE:  ${mae_naive:.2f}\")\n",
    "print(f\"\\nImprovement over Naive:\")\n",
    "print(f\"  RMSE: {(1 - rmse/rmse_naive)*100:+.2f}%\")\n",
    "print(f\"  MAE:  {(1 - mae/mae_naive)*100:+.2f}%\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97027dc5",
   "metadata": {},
   "source": [
    "## 9. Visualize Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dee5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions vs actuals\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Price forecasts\n",
    "forecast_dates = test.index[:len(predictions_price)]\n",
    "axes[0].plot(forecast_dates, actuals_price, label='Actual Price', color='black', linewidth=1.5)\n",
    "axes[0].plot(forecast_dates, predictions_price, label='ARIMA Forecast', color='blue', linewidth=1.5, alpha=0.7)\n",
    "axes[0].set_title(f'ARIMA{best_order} - Gold Price Forecasts (5-Day Ahead)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Price (USD)', fontsize=11)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Forecast errors\n",
    "errors = np.array(actuals_price) - np.array(predictions_price)\n",
    "axes[1].plot(forecast_dates, errors, color='red', linewidth=1)\n",
    "axes[1].axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "axes[1].fill_between(forecast_dates, errors, 0, alpha=0.3, color='red')\n",
    "axes[1].set_title('Forecast Errors', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Error (USD)', fontsize=11)\n",
    "axes[1].set_xlabel('Date', fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd514326",
   "metadata": {},
   "source": [
    "## 10. Save Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ecb496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for comparison\n",
    "results = {\n",
    "    'model': f'ARIMA{best_order}',\n",
    "    'rmse': rmse,\n",
    "    'mae': mae,\n",
    "    'rmse_naive': rmse_naive,\n",
    "    'mae_naive': mae_naive,\n",
    "    'n_predictions': len(predictions_price)\n",
    "}\n",
    "\n",
    "# Save to CSV\n",
    "results_df = pd.DataFrame([results])\n",
    "results_df.to_csv('../models/arima_baseline_results.csv', index=False)\n",
    "\n",
    "# Save model\n",
    "arima_fit.save('../models/arima_baseline_model.pkl')\n",
    "\n",
    "print(\"✓ Model and results saved to 'models/' directory\")\n",
    "print(\"\\nFiles created:\")\n",
    "print(\"  - arima_baseline_results.csv\")\n",
    "print(\"  - arima_baseline_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9de075",
   "metadata": {},
   "source": [
    "## 11. Key Findings\n",
    "\n",
    "**Summary**:\n",
    "1. ARIMA baseline establishes benchmark performance\n",
    "2. Check ACF of squared residuals for ARCH effects\n",
    "3. If present → GARCH extension needed (Notebook 04)\n",
    "4. Next: Add exogenous variables (SARIMAX, Notebook 03)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
